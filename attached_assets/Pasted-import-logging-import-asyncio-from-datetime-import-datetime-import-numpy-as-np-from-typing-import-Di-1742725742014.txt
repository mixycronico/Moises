import logging
import asyncio
from datetime import datetime
import numpy as np
from typing import Dict, List, Any, Optional, Tuple, Union, Set
import pickle
from scipy.optimize import curve_fit
from functools import lru_cache

# Configuración de logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger('genesis.predictive_scaling')

class EfficiencyPrediction:
    """Predicción de eficiencia para un nivel de capital específico."""
    
    def __init__(
        self,
        symbol: str,
        capital_level: float,
        efficiency: float,
        confidence: float = 0.0,
        prediction_type: str = "model",
        metrics: Optional[Dict[str, Any]] = None
    ):
        """Inicializar predicción con validación."""
        if not isinstance(symbol, str) or not symbol:
            raise ValueError("Symbol debe ser una cadena no vacía")
        self.symbol = symbol
        self.capital_level = max(0.0, float(capital_level))
        self.efficiency = max(0.0, min(1.0, float(efficiency)))
        self.confidence = max(0.0, min(1.0, float(confidence)))
        self.prediction_type = prediction_type
        self.metrics = metrics or {}
        self.timestamp = datetime.now()

    def to_dict(self) -> Dict[str, Any]:
        """Convertir predicción a diccionario."""
        return {
            "symbol": self.symbol,
            "capital_level": self.capital_level,
            "efficiency": self.efficiency,
            "confidence": self.confidence,
            "prediction_type": self.prediction_type,
            "metrics": self.metrics,
            "timestamp": self.timestamp.isoformat()
        }


class PredictiveModel:
    """Modelo predictivo para la eficiencia de capital con optimización."""
    
    SUPPORTED_MODELS = {'linear', 'polynomial', 'exponential'}
    
    def __init__(self, symbol: str, model_type: str = "polynomial"):
        """Inicializar modelo con validación de tipo."""
        if model_type not in self.SUPPORTED_MODELS:
            raise ValueError(f"Tipo de modelo '{model_type}' no soportado. Opciones: {self.SUPPORTED_MODELS}")
        self.symbol = symbol
        self.model_type = model_type
        self.parameters: Dict[str, float] = {}
        self.data_points: List[Tuple[float, float]] = []
        self.r_squared = 0.0
        self.mean_error = 0.0
        self.max_error = 0.0
        self.valid_range = (0.0, float('inf'))
        self.training_timestamp: Optional[datetime] = None
        self.saturation_point: Optional[float] = None
        self.is_trained = False

    def add_data_point(self, capital: float, efficiency: float) -> None:
        """Añadir punto de datos con validación."""
        capital = max(0.0, float(capital))
        efficiency = max(0.0, min(1.0, float(efficiency)))
        for i, (c, _) in enumerate(self.data_points):
            if abs(c - capital) < 0.001:
                self.data_points[i] = (capital, efficiency)
                return
        self.data_points.append((capital, efficiency))
        self.is_trained = False

    def train(self) -> bool:
        """Entrenar modelo con manejo de errores y optimización."""
        if len(self.data_points) < 3:
            logger.warning(f"Modelo {self.symbol}: Insuficientes puntos de datos ({len(self.data_points)})")
            return False

        x = np.array([p[0] for p in self.data_points], dtype=np.float64)
        y = np.array([p[1] for p in self.data_points], dtype=np.float64)

        try:
            if self.model_type == 'linear':
                a, b = np.polyfit(x, y, 1)
                self.parameters = {'a': float(a), 'b': float(b)}
                y_pred = a * x + b

            elif self.model_type == 'exponential':
                def exp_func(x, a, b, c):
                    return a * np.exp(-b * x) + c
                
                popt, _ = curve_fit(exp_func, x, y, p0=[1.0, 0.001, 0.1], maxfev=10000)
                self.parameters = {'a': float(popt[0]), 'b': float(popt[1]), 'c': float(popt[2])}
                y_pred = exp_func(x, *popt)
                self._set_saturation_point(exp_func, x, *popt)

            else:  # polynomial
                coeffs = np.polyfit(x, y, 2)
                self.parameters = {'a': float(coeffs[0]), 'b': float(coeffs[1]), 'c': float(coeffs[2])}
                y_pred = coeffs[0] * x**2 + coeffs[1] * x + coeffs[2]
                if coeffs[0] < 0:
                    self.saturation_point = float(-coeffs[1] / (2 * coeffs[0]))

            self._calculate_metrics(x, y, y_pred)
            self.training_timestamp = datetime.now()
            self.is_trained = True
            return True

        except Exception as e:
            logger.error(f"Error entrenando modelo {self.symbol}: {e}")
            return False

    def _set_saturation_point(self, func, x: np.ndarray, *params) -> None:
        """Calcular punto de saturación para modelo exponencial."""
        xs = np.linspace(x[-1], x[-1] * 10, 1000)
        ys = func(xs, *params)
        saturated = np.where(ys < 0.5)[0]
        self.saturation_point = float(xs[saturated[0]]) if saturated.size > 0 else None

    def _calculate_metrics(self, x: np.ndarray, y: np.ndarray, y_pred: np.ndarray) -> None:
        """Calcular métricas del modelo."""
        residuals = y - y_pred
        ss_res = np.sum(residuals**2)
        ss_tot = np.sum((y - np.mean(y))**2)
        self.r_squared = 1 - (ss_res / ss_tot) if ss_tot > 0 else 0.0
        self.mean_error = float(np.mean(np.abs(residuals)))
        self.max_error = float(np.max(np.abs(residuals)))
        self.valid_range = (float(x.min()), float(x.max()) * 2)

    @lru_cache(maxsize=128)
    def predict(self, capital: float) -> float:
        """Predecir eficiencia con caché."""
        capital = max(0.0, float(capital))
        if not self.is_trained and not self.train():
            return self._fallback_prediction(capital)
        
        if self.model_type == 'linear':
            return max(0.0, min(1.0, self.parameters['a'] * capital + self.parameters['b']))
        elif self.model_type == 'exponential':
            a, b, c = (self.parameters[k] for k in ('a', 'b', 'c'))
            return max(0.0, min(1.0, a * np.exp(-b * capital) + c))
        else:  # polynomial
            a, b, c = (self.parameters[k] for k in ('a', 'b', 'c'))
            pred = a * capital**2 + b * capital + c
            if capital > self.valid_range[1] and a < 0:
                pred -= 0.1 * (capital - self.valid_range[1]) / self.valid_range[1]
            return max(0.0, min(1.0, pred))

    def _fallback_prediction(self, capital: float) -> float:
        """Predicción de respaldo cuando no hay modelo entrenado."""
        if not self.data_points:
            return 0.5
        closest = min(self.data_points, key=lambda p: abs(p[0] - capital))
        return closest[1]

    def get_confidence(self, capital: float) -> float:
        """Calcular confianza con optimización."""
        if not self.is_trained or not self.data_points:
            return 0.1
        
        model_quality = max(0.1, min(1.0, self.r_squared))
        distances = [abs(p[0] - capital) / max(1.0, capital) for p in self.data_points]
        proximity_factor = np.exp(-3 * min(distances))
        
        range_factor = 1.0 if self.valid_range[0] <= capital <= self.valid_range[1] else \
            np.exp(-2 * max(0, (capital - self.valid_range[1]) / max(1.0, self.valid_range[1])))
        
        return max(0.1, min(0.95, 0.7 * model_quality + 0.2 * proximity_factor + 0.1 * range_factor))


class PredictiveScalingEngine:
    """Motor predictivo para escalabilidad adaptativa con mejoras."""
    
    def __init__(self, config: Optional[Dict[str, Any]] = None):
        """Inicializar motor predictivo."""
        self.logger = logger
        self.config = config or {}
        self.models: Dict[str, PredictiveModel] = {}
        self.prediction_cache: Dict[str, Dict[float, EfficiencyPrediction]] = {}
        
        self.default_model_type = self.config.get('default_model_type', 'polynomial')
        self.cache_ttl = self.config.get('cache_ttl', 300)
        self.auto_train = self.config.get('auto_train', True)
        self.confidence_threshold = max(0.1, min(1.0, self.config.get('confidence_threshold', 0.7)))
        
        self.stats = {
            "prediction_requests": 0,
            "cache_hits": 0,
            "model_trainings": 0,
            "optimization_runs": 0,
            "errors": 0
        }

    async def add_efficiency_record(
        self, 
        symbol: str, 
        capital: float, 
        efficiency: float, 
        metrics: Optional[Dict[str, Any]] = None
    ) -> None:
        """Añadir registro de eficiencia de forma asíncrona."""
        try:
            model = self.models.setdefault(symbol, PredictiveModel(symbol, self.default_model_type))
            model.add_data_point(capital, efficiency)
            if symbol in self.prediction_cache:
                self.prediction_cache[symbol].clear()
            if self.auto_train and len(model.data_points) >= 3:
                if model.train():
                    self.stats["model_trainings"] += 1
        except Exception as e:
            self.stats["errors"] += 1
            self.logger.error(f"Error añadiendo registro para {symbol}: {e}")

    async def predict_efficiency(self, symbol: str, capital: float) -> EfficiencyPrediction:
        """Predecir eficiencia con manejo asíncrono."""
        self.stats["prediction_requests"] += 1
        cache_key = (symbol, capital)
        
        if symbol in self.prediction_cache and capital in self.prediction_cache[symbol]:
            pred = self.prediction_cache[symbol][capital]
            if (datetime.now() - pred.timestamp).total_seconds() < self.cache_ttl:
                self.stats["cache_hits"] += 1
                return pred

        try:
            model = self.models.setdefault(symbol, PredictiveModel(symbol, self.default_model_type))
            if not model.is_trained:
                await asyncio.to_thread(model.train)  # Entrenar en hilo separado
            
            efficiency = model.predict(capital)
            confidence = model.get_confidence(capital)
            pred = EfficiencyPrediction(
                symbol=symbol,
                capital_level=capital,
                efficiency=efficiency,
                confidence=confidence,
                prediction_type="model" if model.is_trained else "fallback",
                metrics={"model_type": model.model_type, "r_squared": model.r_squared}
            )
            
            self.prediction_cache.setdefault(symbol, {})[capital] = pred
            return pred
        except Exception as e:
            self.stats["errors"] += 1
            self.logger.error(f"Error prediciendo para {symbol}: {e}")
            return EfficiencyPrediction(symbol, capital, 0.5, 0.1, "error")

    async def optimize_allocation(
        self,
        symbols: List[str],
        total_capital: float,
        min_efficiency: float = 0.7
    ) -> Dict[str, float]:
        """Optimizar asignación con ejecución asíncrona."""
        if not symbols or total_capital <= 0:
            return {}
        
        self.stats["optimization_runs"] += 1
        allocation: Dict[str, float] = {}
        
        try:
            min_capital = max(100.0, total_capital / 20)
            max_capital = total_capital / max(1, len(symbols) - 1)
            levels = np.linspace(min_capital, max_capital, 10).tolist()
            
            # Predicciones en paralelo
            tasks = [self.predict_efficiency(s, l) for s in symbols for l in levels]
            predictions = await asyncio.gather(*tasks)
            symbol_curves = {s: [] for s in symbols}
            idx = 0
            for s in symbols:
                for l in levels:
                    pred = predictions[idx]
                    if pred.confidence >= self.confidence_threshold:
                        symbol_curves[s].append((l, pred.efficiency))
                    idx += 1

            valid_symbols = [s for s in symbols if len(symbol_curves[s]) >= 3]
            if not valid_symbols:
                return {s: total_capital / len(symbols) for s in symbols}

            # Cálculo optimizado de utilidad marginal
            marginal_utility = await asyncio.to_thread(self._compute_marginal_utility, symbol_curves, valid_symbols)
            
            # Asignación incremental
            remaining_capital = total_capital
            unallocated_symbols = set(valid_symbols)
            for symbol in unallocated_symbols:
                allocation[symbol] = min_capital
                remaining_capital -= min_capital

            step_size = remaining_capital / 20
            for _ in range(20):
                if not unallocated_symbols or remaining_capital < step_size:
                    break
                current_utility = await asyncio.to_thread(self._compute_current_utility, allocation, marginal_utility, unallocated_symbols)
                total_utility = sum(max(0, u) for u in current_utility.values())
                weights = {s: max(0, u) / total_utility if total_utility > 0 else 1 / len(unallocated_symbols) 
                          for s, u in current_utility.items()}
                
                for symbol in list(unallocated_symbols):
                    to_add = step_size * weights.get(symbol, 0)
                    allocation[symbol] += to_add
                    remaining_capital -= to_add
                    pred = await self.predict_efficiency(symbol, allocation[symbol])
                    if pred.efficiency < min_efficiency:
                        unallocated_symbols.remove(symbol)

            if remaining_capital > 0 and unallocated_symbols:
                per_symbol = remaining_capital / len(unallocated_symbols)
                for symbol in unallocated_symbols:
                    allocation[symbol] += per_symbol

            # Ajuste final
            allocated = sum(allocation.values())
            if abs(allocated - total_capital) > 0.01:
                scale_factor = total_capital / allocated
                for symbol in allocation:
                    allocation[symbol] *= scale_factor

            return allocation
        except Exception as e:
            self.stats["errors"] += 1
            self.logger.error(f"Error optimizando asignación: {e}")
            return {}

    @staticmethod
    def _compute_marginal_utility(symbol_curves: Dict[str, List[Tuple[float, float]]], valid_symbols: List[str]) -> Dict[str, List[Tuple[float, float]]]:
        """Calcular utilidad marginal en un hilo separado."""
        marginal_utility = {}
        for symbol in valid_symbols:
            curve = symbol_curves[symbol]
            marginal_utility[symbol] = []
            for i in range(1, len(curve)):
                cap1, eff1 = curve[i-1]
                cap2, eff2 = curve[i]
                cap_mid = (cap1 + cap2) / 2
                derivative = (eff2 - eff1) / (cap2 - cap1)
                utility = derivative * ((eff1 + eff2) / 2)
                marginal_utility[symbol].append((cap_mid, utility))
        return marginal_utility

    @staticmethod
    def _compute_current_utility(allocation: Dict[str, float], marginal_utility: Dict[str, List[Tuple[float, float]]], symbols: Set[str]) -> Dict[str, float]:
        """Calcular utilidad actual."""
        current_utility = {}
        for symbol in symbols:
            current_cap = allocation[symbol]
            utility_curve = marginal_utility[symbol]
            closest = min(utility_curve, key=lambda x: abs(x[0] - current_cap))
            current_utility[symbol] = closest[1]
        return current_utility