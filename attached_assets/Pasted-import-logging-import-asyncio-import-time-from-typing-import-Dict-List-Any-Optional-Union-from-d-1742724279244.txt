import logging
import asyncio
import time
from typing import Dict, List, Any, Optional, Union
from dataclasses import dataclass
from decimal import Decimal
from datetime import datetime, timedelta
import pandas as pd
import numpy as np
from concurrent.futures import ThreadPoolExecutor
import aioredis  # Para Redis
import asyncpg  # Para PostgreSQL
import unittest
from unittest.mock import AsyncMock, patch

# Configuración inicial para monitoreo (Prometheus-like)
class Metrics:
    def __init__(self):
        self.registry = {}
    
    def gauge(self, name: str, value: float) -> None:
        self.registry[name] = value
    
    def increment(self, name: str) -> None:
        self.registry[name] = self.registry.get(name, 0) + 1
    
    def get_metrics(self) -> Dict[str, float]:
        return self.registry.copy()

metrics = Metrics()

# Configuración de la base de datos PostgreSQL
async def get_db_config() -> Dict[str, Any]:
    conn = await asyncpg.connect(
        user='your_user',
        password='your_password',
        database='genesis_config',
        host='localhost'
    )
    config = await conn.fetchrow(
        'SELECT * FROM strategy_config WHERE id = $1', 1
    )
    await conn.close()
    return dict(config) if config else {
        'capital_base': 10000.0,
        'efficiency_threshold': 0.85,
        'max_symbols_small': 5,
        'max_symbols_large': 15,
        'timeframes': ["15m", "1h", "4h", "1d"],
        'reallocation_interval_hours': 6,
        'saturation_default': 1000000.0
    }

@dataclass
class InstrumentMetrics:
    """Clase de datos para métricas de instrumentos"""
    market_cap: float = 0.0
    volume_24h: float = 0.0
    liquidity_score: float = 0.5
    final_score: float = 0.5
    current_price: float = 0.0

class CapitalScalingManager:
    """Gestor de escalabilidad de capital con Redis y monitoreo"""
    
    def __init__(self, config: Dict[str, Any]):
        self.capital_inicial = max(0.0, config['capital_base'])
        self.umbral_eficiencia = min(1.0, max(0.0, config['efficiency_threshold']))
        self.logger = setup_logging("genesis.strategy.capital_scaling")
        self.config = config
        
        self.registros_eficiencia: Dict[str, Dict[float, float]] = {}
        self.puntos_saturacion: Dict[str, float] = {}
        self.historial_distribucion: List[Dict[str, Any]] = []
        
        self.executor = ThreadPoolExecutor(max_workers=4)
        self.redis: Optional[aioredis.Redis] = None
        
        self.metricas_rendimiento = {
            "eficiencia_promedio": 1.0,
            "utilizacion_capital": 1.0,
            "factor_escala": 1.0,
            "entropia_asignacion": 0.0,
            "registros_distribucion": 0,
            "ultima_actualizacion": datetime.now()
        }
        
        self.logger.info(f"Inicializado con capital: ${self.capital_inicial:,.2f}")

    async def setup_redis(self):
        """Configurar conexión a Redis"""
        self.redis = await aioredis.create_redis_pool('redis://localhost')
    
    async def close_redis(self):
        """Cerrar conexión a Redis"""
        if self.redis:
            self.redis.close()
            await self.redis.wait_closed()

    async def calculate_optimal_allocation(
        self,
        capital_disponible: float,
        instrumentos: List[str],
        metricas: Dict[str, InstrumentMetrics]
    ) -> Dict[str, float]:
        """Calcular distribución óptima con caché y métricas"""
        try:
            start_time = time.time()
            capital_disponible = max(0.0, capital_disponible)
            if not instrumentos or capital_disponible <= 0:
                self.logger.warning("Entrada inválida para asignación")
                return {}

            factor_escala = max(1.0, capital_disponible / self.capital_inicial)
            max_instrumentos = self._calcular_max_instrumentos(factor_escala)
            instrumentos_seleccionados = instrumentos[:max_instrumentos]
            
            # Usar Redis para caché
            cached_key = f"saturation:{hash(str(instrumentos_seleccionados))}"
            cached = await self.redis.get(cached_key) if self.redis else None
            if cached:
                asignaciones = pickle.loads(cached)
            else:
                tareas_saturacion = [
                    self._estimate_saturation_point(simbolo, metricas.get(simbolo, InstrumentMetrics()))
                    for simbolo in instrumentos_seleccionados
                ]
                resultados_saturacion = await asyncio.gather(*tareas_saturacion)
                self.puntos_saturacion.update(dict(zip(instrumentos_seleccionados, resultados_saturacion)))
                asignaciones = await self._calcular_asignaciones(capital_disponible, instrumentos_seleccionados)
                
                if self.redis:
                    await self.redis.set(cached_key, pickle.dumps(asignaciones), expire=3600)

            self._actualizar_metricas_rendimiento(capital_disponible, asignaciones)
            self._registrar_distribucion(capital_disponible, factor_escala, asignaciones)
            
            # Registrar métricas
            metrics.gauge("allocation_time_seconds", time.time() - start_time)
            metrics.gauge("capital_utilization", self.metricas_rendimiento["utilizacion_capital"])
            
            return asignaciones
            
        except Exception as e:
            self.logger.error(f"Falló cálculo de asignación: {e}")
            metrics.increment("allocation_errors")
            return {}

    # ... (otros métodos como _calcular_asignaciones, _estimate_saturation_point, etc., permanecen similares)

class AdaptiveScalingStrategy(Strategy):
    """Estrategia de escalabilidad adaptativa con cierre seguro"""
    
    def __init__(self, nombre: str = "adaptive_scaling_strategy", config: Dict[str, Any] = None):
        super().__init__(nombre)
        self.logger = setup_logging(f"strategy.{nombre}")
        self.config = config or {}
        
        self.capital_inicial = max(0.0, self.config.get('capital_base', 10000.0))
        self.capital_actual = self.capital_inicial
        self.max_simbolos = max(1, self.config.get('max_symbols_large', 15))
        self.tiempos = self.config.get('timeframes', ["15m", "1h", "4h", "1d"]).copy()
        
        self.gestor_escalado = CapitalScalingManager(self.config)
        self.intervalo_reasignacion = timedelta(hours=self.config.get('reallocation_interval_hours', 6))
        
        self.posiciones_activas: Dict[str, Dict[str, Any]] = {}
        self.capital_asignado: Dict[str, float] = {}
        self._reset_estado()
        
        # Control de tareas de fondo
        self._background_tasks = []

    async def start(self) -> None:
        """Iniciar estrategia con Redis y monitoreo"""
        try:
            self.logger.info(f"Iniciando estrategia: {self.nombre}")
            await self.gestor_escalado.setup_redis()
            
            if not self.risk_manager:
                self.risk_manager = AdaptiveRiskManager(
                    capital_inicial=self.capital_inicial,
                    max_drawdown_permitido=0.15,
                    volatilidad_base=0.02,
                    capital_allocation_method="adaptive"
                )
            
            if not self.crypto_classifier:
                self.crypto_classifier = TranscendentalCryptoClassifier(
                    capital_inicial=self.capital_inicial
                )
            
            await super().start()
            
            self._background_tasks = [
                asyncio.create_task(self._ejecutar_tarea_fondo(
                    self._actualizar_capital_fondo, "Actualización Capital")),
                asyncio.create_task(self._ejecutar_tarea_fondo(
                    self._monitoreo_mercado_fondo, "Monitoreo Mercado"))
            ]
            
        except Exception as e:
            self.logger.error(f"Falló inicio de estrategia: {e}")
            self.estadisticas["errores"] += 1
            raise

    async def stop(self) -> None:
        """Cierre seguro de la estrategia"""
        self.logger.info(f"Deteniendo estrategia: {self.nombre}")
        self.running = False
        
        # Cancelar tareas de fondo
        for task in self._background_tasks:
            task.cancel()
            try:
                await task
            except asyncio.CancelledError:
                pass
        
        await self.gestor_escalado.close_redis()
        await super().stop()
        self.logger.info(f"Estrategia {self.nombre} detenida")

    # ... (otros métodos permanecen similares)

# Pruebas Unitarias
class TestCapitalScalingManager(unittest.TestCase):
    def setUp(self):
        self.config = {
            'capital_base': 10000.0,
            'efficiency_threshold': 0.85,
            'max_symbols_small': 5,
            'max_symbols_large': 15
        }
        self.manager = CapitalScalingManager(self.config)
    
    async def test_calculate_optimal_allocation(self):
        instrumentos = ["BTC", "ETH"]
        metricas = {
            "BTC": InstrumentMetrics(market_cap=1000000, volume_24h=500000),
            "ETH": InstrumentMetrics(market_cap=500000, volume_24h=200000)
        }
        asignaciones = await self.manager.calculate_optimal_allocation(20000, instrumentos, metricas)
        self.assertTrue(isinstance(asignaciones, dict))
        self.assertEqual(len(asignaciones), 2)
        self.assertTrue(all(v >= 0 for v in asignaciones.values()))

    @patch('aioredis.create_redis_pool', new_callable=AsyncMock)
    async def test_redis_cache(self, mock_redis):
        mock_redis.return_value.get.return_value = None
        await self.manager.setup_redis()
        self.assertIsNotNone(self.manager.redis)

if __name__ == "__main__":
    unittest.main()